{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('ggplot')\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "import networkx as nx\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='JCrobe', api_key='vZ65FhHdcxZEuQik1HBM')\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"FWBF_NTDS_Graphics.png\" alt=\"Alt text that describes the graphic\" title=\"FWBF_NTDS_Graphics\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**:  Music is something universal and has been known for connecting people for a long time. In the age when diversity in music industry is at its peak, it seems that music has lost its universality and people's musical taste varies to a great extent. In this project, we seek to analyse whether music truly connects people and how one's musical taste is reflected in one's friendships. Using network analysis tools, we want to understand if real friends also have greater similarity in music taste, and how this diffuses throught their friendships. \\\\ After this, we use classification techniques to suggest a tool that can be used by artists and music producers to estimate how popular their music track will be before they even release it. We then test our tool on the different clusters of users we defined to see how it performs in different groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: The Spotify_Top_100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you're in need of love, they give you data and affection\n",
    "\n",
    "The first thing we have to do is to load the data previously wrapped using the [Spotify API](https://developer.spotify.com/documentation/web-api/) and the [Spotipy](https://github.com/plamere/spotipy) python library. The data is contained in a different `.csv` file per user, and the data has to be merged into a single datframe to ease the utilisation and analysis.\n",
    "\n",
    "> Note that the data has been gratefully shared by friends of our team. We kept the playlist's names and user as anonymous as possible for the general public, but it needs to be quite transparent for us.\n",
    "\n",
    "So, let's go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of available playlists\n",
    "filenames = os.listdir(os.getcwd()+'/user_data')\n",
    "files_list = [ filename for filename in filenames if filename.endswith('csv') ]\n",
    "\n",
    "# Remove already loaded playlists\n",
    "try:\n",
    "    songs\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    del songs\n",
    "# and load them up in a Data Frame\n",
    "for item in files_list:\n",
    "    try:\n",
    "        songs\n",
    "    except NameError:\n",
    "        songs = pd.read_csv(os.getcwd()+'/user_data/'+item, sep=';')\n",
    "    else:\n",
    "        songs = songs.append(pd.read_csv(os.getcwd()+'/user_data/'+item, sep=';'), ignore_index=True)\n",
    "\n",
    "songs['User'] = songs['Playlist Origin'].map(lambda x: str(x)[:-10])\n",
    "\n",
    "# Drop duplicates of songs that are in more than one playlist\n",
    "songs_unique = songs.drop_duplicates(subset=['Track Id'], keep='first')\n",
    "songs_unique = songs_unique.reset_index(drop=True)\n",
    "\n",
    "# Create a lookup table (can be looked up using the index or the unique Spotify track ID)\n",
    "lookup_table = songs_unique.drop([\n",
    "                             'Unnamed: 0',\n",
    "                             'Playlist Origin',\n",
    "                             'Playlist order',\n",
    "                             'Track Duration MS',\n",
    "                             'Danceability',\n",
    "                             'Energy',\n",
    "                             'Key',\n",
    "                             'Loudness',\n",
    "                             'Mode',\n",
    "                             'Speechiness',\n",
    "                             'Acousticness',\n",
    "                             'Instrumentalness',\n",
    "                             'Liveness',\n",
    "                             'Valence',\n",
    "                             'Tempo',\n",
    "                             'Valence.1',\n",
    "                             'Track_href',\n",
    "                             'Time_signature',\n",
    "                             'uri'], axis=1)\n",
    "# Create a features array (will be used for building graphs)\n",
    "features = songs_unique.drop([\n",
    "                             'Unnamed: 0',\n",
    "                             'Playlist Origin',\n",
    "                             'Playlist order',\n",
    "                             'Artist',\n",
    "                             'Track Name',\n",
    "                             'Album Name',\n",
    "                             'Track Number',\n",
    "                             'Track Id',\n",
    "                             'Track Duration MS',\n",
    "                             'Track_href',\n",
    "                             'Time_signature',\n",
    "                             'uri','Genres','User'], axis=1)\n",
    "# Converting release dates to timestamps (need to have type float on all features)\n",
    "import dateutil.parser\n",
    "timestamps = features['Album Release Date'].apply(lambda s: dateutil.parser.parse(s))\n",
    "features.update({'Album Release Date': timestamps}, raise_conflict=False)\n",
    "features.rename(columns={'Album Release Date': 'Timestamp'}, inplace=True)\n",
    "\n",
    "# Putting it all in numpy array format\n",
    "np_features = np.array(features).astype(float)\n",
    "# Remove mean and divide by std. deviation on each feature\n",
    "np_features = standardize(np_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe into a .csv file\n",
    "file_name = 'spotify_top_100DB/spotify_top_100DB.csv'\n",
    "songs.to_csv(file_name, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis\n",
    "\n",
    "Now that the data is ready to be analysed, let's look into it to see exactly what is inside and what features might help us make meaningful connections.\n",
    "The dataframe columns are the following and corresponds to the response of the Spotify API to a specific request.\n",
    "\n",
    "- **Playlist Origin**: The playlist were the data comes from\n",
    "- **Playlist order**: The rank of the given row on the original playlist\n",
    "- **Artist**: The artist corresponding to the given song, track\n",
    "- **Track Name**: The track name\n",
    "- **Album Name**: The album name of the given song, track ... \n",
    "- **Album Release Date**: ... and its release date\n",
    "- **Track Number**\n",
    "- **Track Popularity**: \n",
    "- **Track Id**\n",
    "- **Track Duration MS**: The duration of the track in milliseconds.\n",
    "\n",
    "- **Danceability**:Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "\n",
    "- **Energy**:Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
    "\n",
    "- **Key**: The key the track is in. Integers map to pitches using standard [Pitch Class notation](https://en.wikipedia.org/wiki/Pitch_class). E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.\n",
    "\n",
    "- **Loudness**: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n",
    "\n",
    "- **Mode**: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "\n",
    "- **Speechiness**: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "\n",
    "- **Acousticness**:A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
    "\n",
    "- **Instrumentalness**: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "\n",
    "- **Liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n",
    "\n",
    "- **Tempo**: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n",
    "\n",
    "- **Valence**: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "- **Track_href**: A link to the Web API endpoint providing full details of the track.\n",
    "\n",
    "- **Time_signature**: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n",
    "\n",
    "- **uri**: \tThe Spotify URI for the track.\n",
    "\n",
    "- **Genres**: A list of the genres the artist is associated with. For example: \"Prog Rock\" , \"Post-Grunge\". (If not yet classified, the array is empty.)\n",
    "\n",
    "- **User**: The user associated with the playlist (no link with Spotify username in that case)\n",
    "\n",
    "\n",
    "[Complete description](https://developer.spotify.com/documentation/web-api/reference/object-model/#audio-features-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The data frame contains %d different songs and %d diffrent artists' % (len(songs['Track Name'].unique()),len(songs['Artist'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the user name from the song dataframe\n",
    "users_df = pd.DataFrame(songs['User'].unique())\n",
    "users_df.columns = ['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a single user data from the song dataframe. If unknown is specified, return the complete choice list.\n",
    "def single_user_dataframe(name): \n",
    "    if name == 'unknown':\n",
    "        print('Which user do you want? Enter corresponding number')\n",
    "        print(users_df['Name'])\n",
    "        selected_one = int(input())\n",
    "        name = users_df.loc[selected_one]['Name']    \n",
    "    user_dataframe = songs[songs['User']==name]\n",
    "    user_name = name\n",
    "    return user_name,user_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the top tracks of a given user, dataframe.\n",
    "def compute_top_tracks(dataframe):\n",
    "    top_tracks = []\n",
    "    top_tracks = dataframe.groupby(['Track Name','Artist']).count() #we group by categories as we want one single quantity per unique category\n",
    "    top_tracks = top_tracks.add_suffix('_count').reset_index() #reset the index to get the original data frame headers\n",
    "    top_tracks = top_tracks.sort_values(by=['Danceability_count'],ascending=False)\n",
    "    top_tracks['All_infos'] = (top_tracks['Artist'] + ': ' + top_tracks['Track Name'])\n",
    "    top_tracks = top_tracks[['All_infos','Danceability_count']].reset_index(drop=True)\n",
    "    top_tracks.columns = ['Item','Count']\n",
    "    return top_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the top tracks of a given dataframe.\n",
    "def compute_top_artists(dataframe):\n",
    "    top_artists = []\n",
    "    top_artists = dataframe.groupby(['Artist']).count() #we group by categories as we want one single quantity per unique category\n",
    "    top_artists = top_artists.add_suffix('_count').reset_index() #reset the index to get the original data frame headers\n",
    "    top_artists = top_artists.sort_values(by=['Danceability_count'],ascending=False)\n",
    "    top_artists = top_artists[['Artist','Danceability_count']].reset_index(drop=True)\n",
    "    top_artists.columns = ['Item','Count']\n",
    "    return top_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the top n items of a given dataframe.\n",
    "def plot_tops(tops,nitems,title,y_axe):\n",
    "    fig, ax = plt.subplots()\n",
    "    chosen_number = nitems\n",
    "    y_pos = np.arange(chosen_number)\n",
    "    ax.barh(y_pos, tops.Count[:chosen_number], align='center', ecolor='black')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(tops['Item'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Number of occurences')\n",
    "    ax.set_ylabel(y_axe)\n",
    "    ax.set_title(title)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposed the dataframe to make it fit the plotly radarchart requierements.\n",
    "def get_transposed(user_dataframe):\n",
    "    transposed = user_dataframe.groupby(['Playlist Origin']).mean()\n",
    "    transposed = transposed[['Track Popularity','Danceability','Energy','Acousticness','Instrumentalness','Liveness','Speechiness','Valence']]\n",
    "    transposed = transposed.T.reset_index()\n",
    "    transposed.columns = ['Score','Value']\n",
    "    transposed.loc[1:10,['Value']]=transposed['Value'][1:10]*100\n",
    "    return transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a radar plot of the percentages\n",
    "def make_radar_chart(user_dataframe,user_name):\n",
    "    transposed = get_transposed(user_dataframe)\n",
    "    data = [\n",
    "        go.Scatterpolar(\n",
    "            r = transposed['Value'],\n",
    "            theta = transposed['Score'],  \n",
    "            fill = 'toself',\n",
    "            name = user_name\n",
    "        )\n",
    "    ]\n",
    "    layout = go.Layout(\n",
    "        polar = dict(\n",
    "            radialaxis = dict(\n",
    "                visible = True\n",
    "            )\n",
    "        ),\n",
    "        showlegend = False\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename = user_name+'_single_analysis')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the user summary corresponding to the given user_name and dataframe\n",
    "def user_summary(user_name,user_dataframe):\n",
    "    print('In 2018, the playlist from %s contained %d different songs among %d different artists' % (user_name,len(user_dataframe['Track Name'].unique()),len(user_dataframe['Artist'].unique())))\n",
    "    \n",
    "    user_top_artists = compute_top_artists(user_dataframe)\n",
    "    plot_tops(user_top_artists,10,user_name+' Top Artists','Name of the artist')\n",
    "    \n",
    "    mean_features = user_dataframe.groupby(['Playlist Origin']).mean()\n",
    "    print(user_name,'in stats:')\n",
    "    print('\\tPopularity score is : %.2f' %(mean_features['Track Popularity']))\n",
    "    print('\\tDanceability score is : %.2f' %(mean_features['Danceability']))\n",
    "    print('\\tEnergy score is : %.2f' %(mean_features['Energy']))\n",
    "    print('\\tLoudness score is : %.2f' %(mean_features['Loudness']))\n",
    "    print('\\tSpeechiness score is : %.2f' %(mean_features['Speechiness']))\n",
    "    print('\\tAcousticness score is : %.2f' %(mean_features['Acousticness']))\n",
    "    print('\\tInstrumentalness score is : %.2f' %(mean_features['Instrumentalness']))\n",
    "    print('\\tLiveness score is : %.2f' %(mean_features['Liveness']))\n",
    "    print('\\tTempo score is : %.2f' %(mean_features['Tempo']))\n",
    "    print('\\tValence score is : %.2f' %(mean_features['Valence']))\n",
    "    \n",
    "    make_radar_chart(user_dataframe,user_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load some data from a specific user. \n",
    "user_name,user_dataframe = single_user_dataframe('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load some data with the knowledge of who to extract.\n",
    "JC,JC_dataframe = single_user_dataframe('JC')\n",
    "AsN,AsN_dataframe = single_user_dataframe('AsN')\n",
    "AxN,AxN_dataframe = single_user_dataframe('AxN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a radar plot (using plotly)\n",
    "transposed_JC = get_transposed(JC_dataframe)\n",
    "transposed_AsN = get_transposed(AsN_dataframe)\n",
    "transposed_AxN = get_transposed(AxN_dataframe)\n",
    "data = [\n",
    "    go.Scatterpolar(\n",
    "      r = transposed_JC['Value'],\n",
    "      theta = transposed_JC['Score'],\n",
    "      fill = 'toself',\n",
    "      name = JC\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "      r = transposed_AsN['Value'],\n",
    "      theta = transposed_AsN['Score'],\n",
    "      fill = 'toself',\n",
    "      name = AsN\n",
    "    ),    \n",
    "    go.Scatterpolar(\n",
    "      r = transposed_AxN['Value'],\n",
    "      theta = transposed_AxN['Score'],\n",
    "      fill = 'toself',\n",
    "      name = AxN\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "  polar = dict(\n",
    "    radialaxis = dict(\n",
    "      visible = True,\n",
    "    )\n",
    "  ),\n",
    "  showlegend = False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename = \"Nilsson\"+'_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data and display summary\n",
    "MM,MM_dataframe = single_user_dataframe('MM')\n",
    "user_summary(MM,MM_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the mean and median of the quantitative variables of the dataframe.\n",
    "mean_features_all_users = songs.groupby(['Playlist Origin']).mean().reset_index()\n",
    "med_features_all_users = songs.groupby(['Playlist Origin']).median().reset_index()\n",
    "\n",
    "#Sort the users based on the median of a given criteria.\n",
    "parameter_tosort = 'Danceability'\n",
    "sorted_by_med = med_features_all_users.sort_values(by=[parameter_tosort],ascending=False).reset_index()\n",
    "print('Top 3 users using the parameter %s are:' %(parameter_tosort))\n",
    "print(sorted_by_med.loc[0:2,['Playlist Origin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the top tracks and related artists for the whole dataframe\n",
    "top_tracks = compute_top_tracks(songs)\n",
    "top_artists = compute_top_artists(songs)\n",
    "\n",
    "plot_tops(top_tracks,20,'2018 Top Tracks','Name of the track')\n",
    "plot_tops(top_artists,20,'2018 Top Artists','Name of the artist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song adjacency matrix construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the importance of the features, and construct an adjacency matrix based on the relative weights of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp (0), Popularity (1), Danceability (2), Energy (3), Key (4), Loudness (5), Mode (6), Speechiness (7)\n",
    "# Acousticness (8), Instrumentalness (9), Liveness (10), Valence (11), Tempo (12)\n",
    "\n",
    "# Define relative importance of the features before defining a metric between any pair of them...\n",
    "ponderation = np.ones((np_features.shape[1]))\n",
    "ponderation[2] = 3\n",
    "ponderation[4] = 0\n",
    "ponderation[8] = 2\n",
    "ponderation[9] = 2\n",
    "ponderation[10] = 2\n",
    "\n",
    "# Apply ponderation to features (weights will broadcast to all lines of the features array)\n",
    "np_features_pondered = np_features*ponderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ponderation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an adjacency matrix based of cosine similarity of tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the distance between all pairs of songs and building the adjacency matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "adjacency = squareform(pdist(np_features_pondered,metric='cosine'))\n",
    "\n",
    "# Putting some order to the chaos\n",
    "# Strong links between similar songs, weak links otherwise and all links between 0 and 1\n",
    "adjacency = 1.5*(1-adjacency);\n",
    "# Remove negative links\n",
    "adjacency[adjacency < 0] = 0.0\n",
    "# Bound all links to 1.0\n",
    "adjacency[adjacency > 1.0] = 1.0\n",
    "# Remove self links\n",
    "np.fill_diagonal(adjacency, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.title('Adjacency visualization')\n",
    "im = ax.imshow(adjacency, cmap='YlOrBr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: Maybe what could be great would be to use the same concepts as in Milestone 3 (we have the work of the best group on github), on that dataset, spatial embedding and so on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_link_no = adjacency.shape[0]*adjacency.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then show some statistics on our music adjacency graph to see how strong and frequent the connections are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Links with non-zero weight : %d per cent' % int(100*np.count_nonzero(adjacency!=0)/max_link_no))\n",
    "print('Links with weight one : %d per cent' % int(100*np.count_nonzero(adjacency==1)/max_link_no))\n",
    "print('Mean of non-zero links : %.3f' % np.mean(adjacency!=0))\n",
    "print('Standard deviation of non-zero links : %.3f' % np.std(adjacency!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_adjacency = adjacency.copy()\n",
    "for line in range(significant_adjacency.shape[0]):\n",
    "    significant_adjacency[line, significant_adjacency[line,:].argsort()[0:-13:1]] = 0.0\n",
    "significant_adjacency = 0.5*(significant_adjacency + significant_adjacency.T)\n",
    "#significant_adjacency[significant_adjacency<395] = 0.0\n",
    "#significant_adjacency[significant_adjacency>390] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_songs_unique = nx.from_numpy_matrix(significant_adjacency)\n",
    "G_songs_unique.name = 'Unique songs'\n",
    "print(nx.info(G_songs_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_visualizer_from_npadj(Graph,title):\n",
    "    #Some global parameters to pass in attributes.\n",
    "    options = {\n",
    "        'node_color': 'black',\n",
    "        'node_size': 50,\n",
    "        'line_color': 'grey',\n",
    "        'linewidths': 0,\n",
    "        'width': 0.1,\n",
    "    }\n",
    "    #Display the graph with desired layout.\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    nx.draw(Graph, pos=nx.spring_layout(Graph),**options)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.savefig(\"test.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_visualizer_from_npadj(G_songs_unique, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: The Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it last forever, friendship never ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to construct a network based on real friendship relations. To do so, an adjacency matrix $A$ was constructed offline and imported on the notebook. It contains information about the relationship between the Spotify users. It is a binary matrix that can be read as follow:\n",
    "\n",
    "- If the users $i$ and $j$ known each other more that meeting only one time, $A(i,j)$ is equal to one\n",
    "- If they don't, $A(i,j)$ is equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of the user_adjacency_file and processing to make it symmetric. (Only one diagonal was filled by hand)\n",
    "adjacency_df = pd.read_csv('user_adjacency.csv', sep=',').fillna(0)\n",
    "adjacency_df = adjacency_df.set_index('Unnamed: 0')\n",
    "adjacency_df.index.names = ['Users']\n",
    "adjacency_complete = adjacency_df + adjacency_df.T\n",
    "np.fill_diagonal(adjacency_complete.values, 0) #no self loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FRIENDSHIP MATRIX DISPLAY ##\n",
    "# According to the given color bar, the higher the score the closer the two playlists.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(adjacency_complete, cmap='YlOrBr')\n",
    "\n",
    "# Each tick corresponds to the corresponding user.\n",
    "ax.set_xticks(np.arange(adjacency_complete.shape[1]))\n",
    "ax.set_yticks(np.arange(adjacency_complete.shape[0]))\n",
    "ax.set_xticklabels(adjacency_complete.columns)\n",
    "ax.set_yticklabels(adjacency_complete.index)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "divider = make_axes_locatable(ax)\n",
    "plt.title(\"Friendship Matrix\")\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = fig.colorbar(im,cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the matrix visulatization of the friendship relations. When the square is brown, it means that the two users are related and no otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH CONSTRUCTION ##\n",
    "to_graph_from = adjacency_complete #the adjacency to generate the graph from.\n",
    "\n",
    "# From the adjacency generated by the users/artists graphs\n",
    "F = nx.from_pandas_adjacency(to_graph_from)\n",
    "F.name = 'Friends Graph'\n",
    "print(nx.info(F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 23 friends, the average degree is 4.08, meaning that each one of the user is related to an average 4 other people. The distribution however, as represented by the matrix visualization above shows that the distribution of degrees is wide, with some users being very connected and others having only 1 connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH VISUALIZATION ##\n",
    "#Some global parameters to pass in attributes.\n",
    "options = {\n",
    "    'node_color': 'cyan',\n",
    "    'node_size': 500,\n",
    "    'line_color': 'black',\n",
    "    'linewidths': 0,\n",
    "    'width': 3\n",
    "}\n",
    "\n",
    "#Display the graph with desired layout and labels\n",
    "plt.figure(figsize = (10, 10))\n",
    "pos=nx.spring_layout(F) # positions for all nodes\n",
    "nx.draw_networkx_nodes(F,pos,cmap=plt.cm.jet,**options)# nodes\n",
    "nx.draw_networkx_edges(F,pos,alpha=0.2,edge_color='grey',**options)# edges\n",
    "nx.draw_networkx_labels(F,pos,font_size=10,font_family='sans-serif',font_color='k',**options)# labels\n",
    "plt.title('Friendship Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a visual inspection of the friendship network. We can distinguish a center cluster that is surrounded by smaller groups often connected to the main one by one simple user. This reflects the data collection process given playlists were obtained by asking other friends of several members of our group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the betweenness centrality of the User Graph\n",
    "betweenness = nx.betweenness_centrality(F)\n",
    "\n",
    "# Assign each to an attribute in the User Graph\n",
    "nx.set_node_attributes(F, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "#And the top 5 higher betweeness users are: \n",
    "for user, bw in sorted_betweenness[:5]:\n",
    "    print(user,'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betweenness centrality of a node v is the sum of the fraction of all-pairs shortest paths that pass through v:\n",
    "\n",
    "$$c_B(v) =\\sum_{s,t \\in V} \\frac{\\sigma(s, t|v)}{\\sigma(s, t)}$$\n",
    "\n",
    "where $V$ is the set of nodes, $\\sigma(s, t)$ is the number of shortest $(s, t)-paths$, and $\\sigma(s, t|v)$ is the number of those paths passing through some node v other than s, t. If s = t, $\\sigma(s, t) = 1$, and if $v \\in {s, t}$, $\\sigma(s, t|v) = 0$. More in the [Networkx reference page](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.centrality.betweenness_centrality.html)\n",
    "\n",
    "We used this relationship to distinguish the cohesive users, meaning the ones that you should go to if you want to meet the people of the network that you do not know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the above resutls directly on the graph\n",
    "list_nodes =list(F.nodes())\n",
    "list_nodes.reverse()\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "pos = nx.spring_layout(F)\n",
    "ec = nx.draw_networkx_edges(F, pos, alpha=0.1)\n",
    "nc = nx.draw_networkx_nodes(F, pos, nodelist=list_nodes, node_color=[F.nodes[n][\"betweenness\"] for n in list_nodes],with_labels=True, alpha=0.8, node_shape = '.',node_size = 2000, cmap=plt.cm.jet)\n",
    "lc = nx.draw_networkx_labels(F,pos,font_size=10,font_family='sans-serif',font_color='w')# labels\n",
    "plt.colorbar(nc)\n",
    "plt.title('Betweeness of the users')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig('betweeness.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br>The color gradient represents the betweeness of a given node. In that graph, the result is not surprising as JC was the one to originaly ask friends for data. LaB has also an high score because of the very same reason. The other bluer nodes are basically end nodes, when the data collection chain stopped.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: The Musical Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to see how well the real friendship network correlates with the one generated through musical affinities between users. For that, we will need to construct some basic networks to build our further analysis on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NODE DATAFRAME CONSTRUCTION ##\n",
    "#Extract proper column from playlists and add node caracteristics\n",
    "playlists = pd.DataFrame(songs['Playlist Origin'].unique())\n",
    "playlists['Type'] = 'Playlist'\n",
    "playlists['Color'] = 'orange'\n",
    "\n",
    "#Extract proper column from artists and add node caracteristics\n",
    "artists = pd.DataFrame(songs['Artist'].unique())\n",
    "artists['Type'] = 'Artists'\n",
    "artists['Color'] = 'black'\n",
    "\n",
    "#Extract proper column from tracks and add node caracteristics\n",
    "tracks = pd.DataFrame(songs['Track Name'].unique())\n",
    "#Add some caracteristics\n",
    "tracks['Type'] = 'Titles'\n",
    "tracks['Color'] = 'grey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the users (playlists), artists and tracks into one single dataframe\n",
    "nodes = playlists.append(artists).append(tracks).drop_duplicates(keep='first').reset_index(drop=True)\n",
    "nodes.columns=['Name','Type','Color']\n",
    "nodes.set_index('Name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_visualizer(Graph,title):\n",
    "    #Some global parameters to pass in attributes.\n",
    "    options = {\n",
    "        'node_color': [Graph.node[n]['Color'] for n in Graph.nodes()],\n",
    "        'node_size': 50,\n",
    "        'line_color': 'grey',\n",
    "        'linewidths': 0,\n",
    "        'width': 0.1,\n",
    "    }\n",
    "    #Display the graph with desired layout.\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    nx.draw(Graph, pos=nx.spring_layout(Graph),**options)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User / Artists graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH CONSTRUCTION ##\n",
    "G=nx.from_pandas_edgelist(songs, 'Playlist Origin', 'Artist',edge_attr=None, create_using= nx.Graph())\n",
    "G.name = 'User/Artists Graph'\n",
    "#print(nx.info(G))\n",
    "\n",
    "#Set node attributes from nodes dataframe\n",
    "nx.set_node_attributes(G, nodes['Type'].to_dict(), 'Type')\n",
    "nx.set_node_attributes(G, nodes['Color'].to_dict(), 'Color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH VISUALIZATION ##\n",
    "graph_visualizer(G,'User/Artist Graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br>Here, the orange nodes are the users, and the black one represent the different artists. We can observe that the vast majority of the artists are present in a single playlist linked to a single user. There is nevertheless some artists that are shared by two or more users. This first insight will be developped later, let see the Artist/Track distribution\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artist / Track Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH CONSTRUCTION ##\n",
    "G4=nx.from_pandas_edgelist(songs,'Artist','Track Name')\n",
    "G4.name = 'Artists/Tracks Graph'\n",
    "nx.set_node_attributes(G4, nodes['Type'].to_dict(), 'Type')\n",
    "nx.set_node_attributes(G4,nodes['Color'].to_dict(), 'Color')\n",
    "#print(nx.info(G4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH VISUALIZATION ##\n",
    "graph_visualizer(G4,'Songs/Artist Graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br>Here, we can observe that the mast majority of the artists are contained only one time in the Spotify Data base. Some are present more than that, as we have previously observed in the dataset descriptive analysis. Now, let's put everything together.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User / Artists / Tracks Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDGE DATAFRAME CONSTRUCTION ##\n",
    "#*The edge dataframe to be passed on the graph constructor\n",
    "# The links between users and artists\n",
    "playlist_artists = songs[['Playlist Origin','Artist']]\n",
    "playlist_artists.columns=['Start','End']\n",
    "\n",
    "# The links between artists and tracks\n",
    "artists_tracks = songs[['Artist','Track Name']]\n",
    "artists_tracks.columns=['Start','End']\n",
    "\n",
    "#Merge everything into a single dataframe\n",
    "edges_full = playlist_artists.append(artists_tracks).drop_duplicates(keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH CONSTRUCTION ##\n",
    "G2=nx.from_pandas_edgelist(edges_full,'Start','End')\n",
    "G2.name = 'User/Artists/Tracks Graph'\n",
    "#print(nx.info(G2))\n",
    "\n",
    "#Adding some node attributes to ease the visualization.\n",
    "nx.set_node_attributes(G2, nodes['Type'].to_dict(), 'Type')\n",
    "nx.set_node_attributes(G2, nodes['Color'].to_dict(), 'Color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH VISUALIZATION ##\n",
    "graph_visualizer(G2,'User/Artist/Tracks Graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the graph intp a .gexf file to visualize it.\n",
    "nx.write_gexf(G2,'User_Artist_Tracks.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br> Here is a complete visualization of the dataset, where the users (orange) are linked to to artists (black) linked to songs (grey). This visualization put in front the fact that one tends to listen to more one track per given artist.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who are the closest friends ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the User/Artist graph, we will assess the musical affinities between users. It will be done by conting the number of shortest paths of lenght two between users, meaning the presence of the same artist in the two playlists. In the case where shortest path of lenght two does not exist between users, no link is reported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The similarities dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the playlist name from the song dataframe\n",
    "playlists_list = songs['Playlist Origin'].unique()\n",
    "#Keep only the user initials for further analysis\n",
    "users = [playlists_list[i][:-10] for i in range(0,len(playlists_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIMILARITIES CALCULATIONS ##\n",
    "# Initialization of the differents parameters to assess\n",
    "current = 0 #current user number to analyse.\n",
    "shortest_paths = np.zeros(shape=(len(playlists),len(playlists))) #Length of the shortest paths between users.\n",
    "similarities = np.zeros(shape=(len(playlists),len(playlists))) #Number of direct shortest paths betweenn users.\n",
    "\n",
    "for i in range(0,len(playlists_list)):\n",
    "    for k in range(0,len(playlists_list)):\n",
    "        if playlists_list[k] != playlists_list[i]:\n",
    "            shortest_path = nx.shortest_path_length(G, source=playlists_list[i], target=playlists_list[k])\n",
    "            #print('Link between %s and %s is %d' % (playlists[i],playlists[k],shortest_path))\n",
    "            shortest_paths[i,k] = shortest_path\n",
    "            if shortest_path == 2:\n",
    "                similarities[i,k] = sum(1 for _ in nx.all_shortest_paths(G, source=playlists_list[i], target=playlists_list[k]))\n",
    "    current = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the similarities array into dataframe for readability.\n",
    "similarities_df = pd.DataFrame(similarities)\n",
    "#Associate each row and columns with their users.\n",
    "similarities_df.columns=users\n",
    "similarities_df.index=users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIMILARITIES DISPLAY ##\n",
    "# According to the givene color bar, the higher the score the closer the two playlists.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(similarities_df, cmap='YlOrBr')\n",
    "\n",
    "# Each tick corresponds to the corresponding user.\n",
    "ax.set_xticks(np.arange(similarities_df.shape[1]))\n",
    "ax.set_yticks(np.arange(similarities_df.shape[0]))\n",
    "ax.set_xticklabels(similarities_df.columns)\n",
    "ax.set_yticklabels(similarities_df.index)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "divider = make_axes_locatable(ax)\n",
    "plt.title(\"Matching Matrix\")\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = fig.colorbar(im,cax=cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br> The above visualization presents the number of \"matches\" between users. The more red the color, the more two users are linked. For exemple MC and MM are really strongly linked with around 25 artists shared. On the opposite, DL is not really related to the majority of the people with more that with one or two artists.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Users Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a proper adjacency matrix, we can generate a weighted graph based on it. The stronger the link between two users, the stronger the weight of the edge will be. Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering option if we want the low connectivities no to be taken into account.\n",
    "threshold = 2\n",
    "similarities_df_filtered=similarities_df[similarities_df>=threshold]\n",
    "similarities_df_filtered = similarities_df_filtered.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH CONSTRUCTION ##\n",
    "to_graph_from = similarities_df #the adjacency to generate the graph from.\n",
    "\n",
    "# From the adjacency generated by the users/artists graphs\n",
    "G3 = nx.from_pandas_adjacency(to_graph_from)\n",
    "G3.name = 'Users Graph'\n",
    "print(nx.info(G3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the average degree is already higher in that graph. This is probably due to the fact that 100 songs is a number high enough to be somehow related to a single or more song in another playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAPH VISUALIZATION ##\n",
    "#Some global parameters to pass in attributes.\n",
    "options = {\n",
    "    'node_color': 'white',\n",
    "    'node_size': 500,\n",
    "    'width': [d['weight'] for (u, v, d) in G3.edges(data=True) if d['weight'] > 0]\n",
    "}\n",
    "\n",
    "#Display the graph with desired layout and labels\n",
    "list_edges =list(G3.edges())\n",
    "list_edges.reverse()\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "pos=nx.spring_layout(G3) # positions for all nodes\n",
    "nx.draw_networkx_nodes(G3,pos,node_color='white')# nodes\n",
    "nx.draw_networkx_labels(G3,pos,font_size=10,font_family='sans-serif',font_color='k')# labels\n",
    "nx.draw_networkx_edges(G3,pos,nodelist=list_edges,alpha=0.5,edge_color=[G3.edges[n]['weight'] for n in list_edges],cmap=plt.cm.jet,**options)# edges\n",
    "plt.title('User affinities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEGREE CALCULATIONS ##\n",
    "# Exctraction of the degrees of each users from the User Graphs\n",
    "degrees = dict(G3.degree(G3.nodes()))\n",
    "sorted_degree = sorted(degrees.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "#And the top 5 most linked users  are.. \n",
    "for user, degree in sorted_degree[:]:\n",
    "    print(user,'is linked to', degree, 'people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br> Due to the network structure and the corresponding higher degree, there is visualy an abondance of edges. But the number of links between people can vary greatly from simple (DL or LaB) to triple (MM or MC). This may be explained by the presence of several confidential artists with respect to the trend and popularity numbers in the playlist of certain users. In the graph above, the thicker the line, the higher the degree\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweeness centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TO DO: Get more info about the algorithms and what does it mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the betweenness centrality of the User Graph\n",
    "betweenness = nx.betweenness_centrality(G3)\n",
    "\n",
    "# Assign each to an attribute in the User Graph\n",
    "nx.set_node_attributes(G3, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "#And the top 5 higher betweeness users are: \n",
    "for user, bw in sorted_betweenness[:5]:\n",
    "    print(user,'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the above resutls directly on the graph\n",
    "list_nodes =list(G3.nodes())\n",
    "list_nodes.reverse()\n",
    "plt.figure(figsize = (10, 5))\n",
    "pos = nx.spring_layout(G3)\n",
    "ec = nx.draw_networkx_edges(G3, pos, alpha=0.1)\n",
    "nc = nx.draw_networkx_nodes(G3, pos, nodelist=list_nodes, node_color=[G3.nodes[n][\"betweenness\"] for n in list_nodes],with_labels=True, alpha=0.8, node_shape = '.',node_size = 2000, cmap=plt.cm.jet)\n",
    "lc = nx.draw_networkx_labels(G3,pos,font_size=10,font_family='sans-serif',font_color='w')# labels\n",
    "plt.colorbar(nc)\n",
    "plt.title('Betweeness of the users')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "    It is clear that in the social network, JC and LaB are the points of data collection, demonstrated by their higher betweenness than the rest of the graph. The relationships in the music friendship graph however transcend the social connections and are much more varied. LaB in particular is not a point in the music network that leads to others in the group as she is in the social network. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to do a community analysis, or clustering on the graph. To do so, we use the Louvain method which is based on the optimisation as the algorithm progresses of a quantity called modularity. Modularity is defined as a value between -1 and 1 that measures the density of links inside communities compared to links between communities. For a weighted graph, modularity is defined as:\n",
    "\n",
    "${\\displaystyle Q={\\frac {1}{2m}}\\sum \\limits _{ij}{\\bigg [}A_{ij}-{\\frac {k_{i}k_{j}}{2m}}{\\bigg ]}\\delta (c_{i},c_{j})}$\n",
    "\n",
    "where\n",
    "\n",
    "- $A_{ij}$ represents the edge weight between nodes $i$ and $j$\n",
    "\n",
    "- $k_{i}$ and $k_j$ are the sum of the weights of the edges attached to nodes {\\displaystyle i} $i$ and $j$, respectively\n",
    "\n",
    "- $2m$ is the sum of all of the edge weights in the graph\n",
    "\n",
    "- $c_{i}$ and $c_{j}$ are the communities of the nodes\n",
    "\n",
    "- $\\delta$  is a simple delta function.\n",
    "\n",
    "[Source](https://en.wikipedia.org/wiki/Louvain_Modularity)\n",
    "\n",
    "In the Louvain Method of community detection, first small communities are found by optimizing modularity locally on all nodes, then each small community is grouped into one node and for each community it is tested whether by joining it to a neighboring community, we can obtain a better clustering. The processus is repeated until no more advancement are made. We will use this tool to decect possible communities starting from our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community import community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition the data into communities from the User Graph\n",
    "partition = community_louvain.best_partition(G3)\n",
    "# add it as an attribute to the nodes\n",
    "for n in G3.nodes:\n",
    "    G3.nodes[n][\"louvain\"] = partition[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the partitioning\n",
    "plt.figure(figsize = (10, 5))\n",
    "pos = nx.spring_layout(G3,k=0.2)\n",
    "ec = nx.draw_networkx_edges(G3, pos, alpha=0.2)\n",
    "nc = nx.draw_networkx_nodes(G3, pos, nodelist=F.nodes(), node_color=[G3.nodes[n][\"louvain\"] for n in G3.nodes], with_labels=False, node_size=500, cmap=plt.cm.jet)\n",
    "lc = nx.draw_networkx_labels(G3,pos,font_size=10,font_family='sans-serif',font_color='w',**options)# labels\n",
    "plt.title('Obtained partitioning')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br> From the figure above, we can see that there is three major groups obtained. Knowing the different relationship between users, one can remark that the blue cluster is composed mainly of non-EPFL users, with few links with the main connected friends from the real friendship adjacency. The green cluster contains the _core_ group of student, that are apart some exceptions, close friends. The third cluster is composed of foreign students or friends that live or come from far away from Switzerland. Differences in music culture, ages or simply the fact that these users have only few relation with the major part of the dataset can explain why they are appart in one cluster. It is really interesting to see that without knowing anything about real-life relations, music tastes can lead to cluster of this kind, that are somewhat close to what we get in reality. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>End :</b><br />\n",
    "<br />\n",
    "<br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the clustering of the music based and social based groups, we now run the louvain method on the social network as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition the data into communities from the User Graph\n",
    "partition = community_louvain.best_partition(F)\n",
    "# add it as an attribute to the nodes\n",
    "for n in F.nodes:\n",
    "    F.nodes[n][\"louvain\"] = partition[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the partitioning\n",
    "plt.figure(figsize = (10, 5))\n",
    "pos = nx.spring_layout(F,k=0.2)\n",
    "ec = nx.draw_networkx_edges(F, pos, alpha=0.2)\n",
    "nc = nx.draw_networkx_nodes(F, pos, nodelist=F.nodes(), node_color=[F.nodes[n][\"louvain\"] for n in F.nodes], with_labels=False, node_size=500, cmap=plt.cm.jet)\n",
    "lc = nx.draw_networkx_labels(F,pos,font_size=10,font_family='sans-serif',font_color='w',**options)# labels\n",
    "plt.title('Obtained partitioning')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.optimize_graph_edit_distance(F, G3)\n",
    "nx.graph_edit_distance(F, G3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Popularity Prediction Using FMA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project, we are going to focus on FMA dataset. In particular, we suggest an approach to predict track 'popularity'. Using this predictive model, artists and music producers will be able to estimate the success of their track before actually uploading it to the platform. It will also help them understand what plays an important role in a track's success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "pd.options.display.max_columns = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading and formatting tracks data\n",
    "\n",
    "df=pd.read_csv('tracks.csv', header=None)\n",
    "df.iloc[1,0]='track_id'\n",
    "df.iloc[1,8]='album_listens'\n",
    "df.iloc[1,47]='track_listens'\n",
    "header = df.iloc[1]\n",
    "df=df[3:]\n",
    "df=df.rename(columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping unnecessary features, fixing types\n",
    "\n",
    "df=df.drop(['id','engineer', 'information','tags','bio','website','wikipedia_page','split','genres','genres_all','subset','lyricist',\n",
    "        'publisher','composer','associated_labels','active_year_end','producer','comments'], axis=1)\n",
    "df[['track_id']]=df[['track_id']].astype(int)\n",
    "df[['tracks']]=df[['tracks']].astype(int)\n",
    "df[['bit_rate']]=df[['bit_rate']].astype(int)\n",
    "df[['duration']]=df[['duration']].astype(int)\n",
    "df[['interest']]=df[['interest']].astype(int)\n",
    "df[['track_listens']]=df[['track_listens']].astype(int)\n",
    "df[['album_listens']]=df[['album_listens']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading and formatting echonest dataset\n",
    "echo=pd.read_csv('echonest.csv', engine = 'python',encoding='utf-8', error_bad_lines=False, header=None)\n",
    "echo.iloc[2,0]='track_id'\n",
    "header = echo.iloc[2]\n",
    "echo=echo[4:]\n",
    "echo=echo.rename(columns = header)\n",
    "echo=echo.loc[:,['track_id', 'acousticness', 'danceability', 'energy',\n",
    "       'instrumentalness', 'liveness', 'speechiness', 'tempo', 'valence',\n",
    "       'artist_discovery', 'artist_familiarity', 'artist_hotttnesss','song_currency', 'song_hotttnesss']]\n",
    "echo=echo.astype(float)\n",
    "echo[['track_id']]=echo[['track_id']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merging two tables \n",
    "new_df =df.merge(echo, on='track_id', how='inner')\n",
    "df =new_df.select_dtypes(include=['int64','float64','int32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating feature quantiles\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "##Removing some extreme outliers\n",
    "df=df[df.track_listens<20000]\n",
    "df=df[df.duration<1000]\n",
    "df=df[df.interest<50000]\n",
    "df=df[df.song_currency<0.01]\n",
    "df=df[df.album_listens<80000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on how the number of track listens is distributed. As it can be seen, tracks having more than 5000 listens are a rarity. Average number of the listens is not more than 1242."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.track_listens)\n",
    "plt.title('Distribution of Track Listens')\n",
    "plt.xlabel('Number of Listens')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average number of listens:',np.mean(df.track_listens))\n",
    "print('Maximum number of listens:',np.max(df.track_listens))\n",
    "print('Minimum number of listens:',np.min(df.track_listens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the number of times a track was listened, we decided to design a classification problem with the objective of predicting a popularity score for a track. \n",
    "To that end, we decided to assign 'popularity' scores on a scale of 1 to 5 based on the quantile interval that a track's number of listens falls into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=pd.qcut(df.track_listens,5,labels=False)+1\n",
    "data=df.drop(['track_listens','track_id','album_listens'], axis=1)\n",
    "colnames=data.columns\n",
    "\n",
    "train_X, test_X, train_Y,test_Y = train_test_split(data, target, test_size=0.30, random_state=20)\n",
    "\n",
    "##Standardizing the data\n",
    "std_scale = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X = std_scale.transform(train_X)\n",
    "test_X  = std_scale.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore feature importacne, we run Random Forest Classifier on our data. Note that we omit the variable 'album_listens' in our model as we want this to be useful for new tracks which will not have available number of album listens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier() \n",
    "rf.fit(train_X, train_Y) \n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = colnames,\n",
    "                                    columns=['importance']).sort_values('importance',      ascending=False)\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_X)\n",
    "errors = np.abs(predictions - test_Y)\n",
    "mape = 100 * (errors / test_Y)\n",
    "accuracy = 100 - np.mean(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Narrowing down the features\n",
    "small_data=df[['interest','acousticness','artist_hotttnesss','artist_familiarity']]\n",
    "train_X, test_X, train_Y,test_Y = train_test_split(small_data, target, test_size=0.30, random_state=20)\n",
    "##Standardizing the data\n",
    "std_scale = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X = std_scale.transform(train_X)\n",
    "test_X  = std_scale.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier() \n",
    "rf.fit(train_X, train_Y) \n",
    "predictions = rf.predict(test_X)\n",
    "errors = np.abs(predictions - test_Y)\n",
    "mape = 100 * (errors / test_Y)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 10):  \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(train_X, train_Y)\n",
    "    pred_i = knn.predict(test_X)\n",
    "    error.append(np.mean(pred_i != test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(range(1, 10), error, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Mean Error')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=6)  \n",
    "classifier.fit(train_X, train_Y) \n",
    "y_pred = classifier.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_Y, y_pred))  \n",
    "print(classification_report(test_Y, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.abs(y_pred - test_Y)\n",
    "mape = 100 * (errors / test_Y)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although KNN has descent performance, it did not manage to perform better than Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the FMA Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data= small_data.sample(frac=0.1, random_state=1)\n",
    "target = target.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create an adjacency matrix to visualize popularity \n",
    "\n",
    "# Calculating the distance between song popularity to build adjacency matrix\n",
    "test = small_data\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "distances = squareform(pdist(test, metric='euclidean'))\n",
    "kernel_width = distances.mean()\n",
    "adjacency = np.exp(-1*(distances*2/(kernel_width*2)))\n",
    "\n",
    "# Remove self links\n",
    "np.fill_diagonal(adjacency, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(adjacency.reshape(-1), bins=200)\n",
    "_ = plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajdacency = adjacency.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_sparse = sparse.csr_matrix(adjacency, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_sparse.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the adjacency to graph, visualize clusters\n",
    "P = nx.from_scipy_sparse_matrix(adjacency_sparse)\n",
    "P.name = 'FMA_Graph'\n",
    "print(nx.info(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygsp import plotting\n",
    "import numpy as np\n",
    "from scipy import sparse, spatial\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pygsp import graphs, filters, plotting\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graphs.Graph(adjacency_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.set_coordinates(kind='spring')\n",
    "G.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val, U = sp.linalg.eigh(G.L.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(eig_val, bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Prediction\n",
    "\n",
    "The following code was adapted from the usage file in the git hub for \"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering\". The adjacency matrix from reduced features from the fma dataset was used. \n",
    "https://github.com/mdeff/cnn_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import models, graph, coarsening, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, perm = coarsening.coarsen(adjacency_sparse, levels=3, self_connections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in graphs:\n",
    "    print(i.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data= small_data.astype(np.float32)\n",
    "target= target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= target.values\n",
    "target = target.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y,test_Y = train_test_split(small_data, target, test_size=0.40, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X, test_X, val_Y,test_Y = train_test_split(test_X, test_Y, test_size=0.50, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.values\n",
    "val_X = val_X.values\n",
    "test_X = test_X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train= len(train_X)\n",
    "len(val_X)\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = coarsening.perm_data(train_X, perm)\n",
    "val_X = coarsening.perm_data(val_X, perm)\n",
    "test_X = coarsening.perm_data(test_X, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype(np.float32)\n",
    "val_X = val_X.astype(np.float32)\n",
    "test_X = test_X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [graph.laplacian(adjacency_sparse, normalized=True) for adjacency_sparse in graphs]\n",
    "graph.plot_spectrum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['dir_name']       = 'demo'\n",
    "params['num_epochs']     = 40\n",
    "params['batch_size']     = 100\n",
    "params['eval_frequency'] = 200\n",
    "\n",
    "# Building blocks.\n",
    "params['filter']         = 'chebyshev5'\n",
    "params['brelu']          = 'b1relu'\n",
    "params['pool']           = 'apool1'\n",
    "\n",
    "# Number of classes.\n",
    "C = test_Y.max() + 1\n",
    "\n",
    "# Architecture.\n",
    "params['F']              = [32, 64]  # Number of graph convolutional filters.\n",
    "params['K']              = [20, 20]  # Polynomial orders.\n",
    "params['p']              = [4, 2]    # Pooling sizes.\n",
    "params['M']              = [512, C]  # Output dimensionality of fully connected layers.\n",
    "\n",
    "# Optimization.\n",
    "params['regularization'] = 5e-4\n",
    "params['dropout']        = 1\n",
    "params['learning_rate']  = 1e-5\n",
    "params['decay_rate']     = 0.95\n",
    "params['momentum']       = 0.9\n",
    "params['decay_steps']    = n_train / params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.cgcnn(L, **params)\n",
    "accuracy, loss, t_step = model.fit(train_X, train_Y, val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "ax1.plot(accuracy, 'b.-')\n",
    "ax1.set_ylabel('validation accuracy', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(loss, 'g.-')\n",
    "ax2.set_ylabel('training loss', color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(test_X, test_Y)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<font color='#B8860B'>\n",
    "<b>Interpretation</b>\n",
    "</font>\n",
    "<font color='black'>\n",
    "<br> We do not get exceptionally good results using the CNN of the Spectral Filtering. We have used a reduced dataset due to the computationally intense nature of this function and the creation of the adjacency matrix. \n",
    "With more computational power, more features could be added, and we could increase the number of samples used. \n",
    "At present the CNN is running on only 5 features, and 10% of the possible samples.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
